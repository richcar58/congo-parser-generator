//! Token types and definitions. Generated by CongoCC Parser Generator. Do not edit.

use std::fmt;

/// Token type enumeration
///
/// Represents all possible token types recognized by the lexer.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum TokenType {
    /// Token: EOF
        EOF,
    /// Token: PLUS
        PLUS,
    /// Token: MINUS
        MINUS,
    /// Token: STAR
        STAR,
    /// Token: SLASH
        SLASH,
    /// Token: LPAREN
        LPAREN,
    /// Token: RPAREN
        RPAREN,
    /// Token: _TOKEN_7
        Token7,
    /// Token: _TOKEN_8
        Token8,
    /// Token: _TOKEN_9
        Token9,
    /// Token: _TOKEN_10
        Token10,
    /// Token: INTEGER
        INTEGER,
    /// Invalid token marker
    INVALID,
}

impl fmt::Display for TokenType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            TokenType::EOF => write!(f, "EOF"),
            TokenType::PLUS => write!(f, "PLUS"),
            TokenType::MINUS => write!(f, "MINUS"),
            TokenType::STAR => write!(f, "STAR"),
            TokenType::SLASH => write!(f, "SLASH"),
            TokenType::LPAREN => write!(f, "LPAREN"),
            TokenType::RPAREN => write!(f, "RPAREN"),
            TokenType::Token7 => write!(f, "_TOKEN_7"),
            TokenType::Token8 => write!(f, "_TOKEN_8"),
            TokenType::Token9 => write!(f, "_TOKEN_9"),
            TokenType::Token10 => write!(f, "_TOKEN_10"),
            TokenType::INTEGER => write!(f, "INTEGER"),
            TokenType::INVALID => write!(f, "INVALID"),
        }
    }
}

/// Lexical state enumeration
///
/// Represents different lexical states the lexer can be in.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum LexicalState {
    /// Lexical state: DEFAULT
    DEFAULT,
}

/// A single token in the input stream
///
/// Tokens are the atomic units produced by the lexer. Each token has:
/// - A type (e.g., INTEGER, PLUS, EOF)
/// - An image (the actual text matched)
/// - Position information (begin/end offsets)
/// - Optional links to previous/next tokens
#[derive(Debug, Clone)]
pub struct Token {
    /// The type of this token
    pub token_type: TokenType,
    /// The actual text of this token
    pub image: String,
    /// Absolute offset in the input where this token begins
    pub begin_offset: usize,
    /// Absolute offset in the input where this token ends
    pub end_offset: usize,
    /// Index of the next token (if any)
    pub next: Option<usize>,
    /// Index of the previous token (if any)
    pub previous: Option<usize>,
}

impl Token {
    /// Create a new token
    pub fn new(
        token_type: TokenType,
        image: String,
        begin_offset: usize,
        end_offset: usize,
    ) -> Self {
        Token {
            token_type,
            image,
            begin_offset,
            end_offset,
            next: None,
            previous: None,
        }
    }

    /// Get the length of this token in characters
    pub fn len(&self) -> usize {
        self.end_offset.saturating_sub(self.begin_offset)
    }

    /// Check if this token is empty
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Check if this token is of a specific type
    pub fn is_type(&self, token_type: TokenType) -> bool {
        self.token_type == token_type
    }

    /// Check if this token is one of the specified types
    pub fn is_one_of(&self, types: &[TokenType]) -> bool {
        types.contains(&self.token_type)
    }
}

impl fmt::Display for Token {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}: \"{}\"", self.token_type, self.image)
    }
}

/// Token source trait for tracking token locations
pub trait TokenSource {
    /// Get the line number for a given offset
    fn get_line_from_offset(&self, offset: usize) -> usize;

    /// Get the column number for a given offset
    fn get_column_from_offset(&self, offset: usize) -> usize;
}
